<!DOCTYPE html>
<html>
  <head>
    <title>Bug when applying KB4038782 September CU to Storage Spaces Direct Clusters – Ben Thomas' Blog – Just another Sysadmin's thoughts</title>

        <meta charset="utf-8" />
    <meta content='text/html; charset=utf-8' http-equiv='Content-Type'>
    <meta http-equiv='X-UA-Compatible' content='IE=edge'>
    <meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1.0'>

    
    <meta name="description" content="UPDATE(2017-09-19): Microsoft have officially recognized the bug and have a KB describing the symptoms and workaround much like the below. See here: https://support.microsoft.com/en-us/help/4043361/disks-in-maintenance-mode-status-after-september-cumulative-update-kb

" />
    <meta property="og:description" content="UPDATE(2017-09-19): Microsoft have officially recognized the bug and have a KB describing the symptoms and workaround much like the below. See here: https://support.microsoft.com/en-us/help/4043361/disks-in-maintenance-mode-status-after-september-cumulative-update-kb

" />
    
    <meta name="author" content="Ben Thomas' Blog" />

    
    <meta property="og:title" content="Bug when applying KB4038782 September CU to Storage Spaces Direct Clusters" />
    <meta property="twitter:title" content="Bug when applying KB4038782 September CU to Storage Spaces Direct Clusters" />
    

    <!--[if lt IE 9]>
      <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="alternate" type="application/rss+xml" title="Ben Thomas' Blog - Just another Sysadmin's thoughts" href="/feed.xml" />

    <!-- Created with Jekyll Now - http://github.com/barryclark/jekyll-now -->
  </head>

  <body>
    <div class="wrapper-masthead">
      <div class="container">
        <header class="masthead clearfix">
          <a href="/" class="site-avatar"><img src="https://raw.githubusercontent.com/barryclark/jekyll-now/master/images/jekyll-logo.png" /></a>

          <div class="site-info">
            <h1 class="site-name"><a href="/">Ben Thomas' Blog</a></h1>
            <p class="site-description">Just another Sysadmin's thoughts</p>
          </div>

          <nav>
            <a href="/">Blog</a>
            <a href="/about">About</a>
          </nav>
        </header>
      </div>
    </div>

    <div id="main" role="main" class="container">
      <article class="post">
  <h1>Bug when applying KB4038782 September CU to Storage Spaces Direct Clusters</h1>

  <div class="tags">
    
    
        <span class="tag">
            <a href="/category/Storage Spaces Direct">#Storage Spaces Direct</a>
        </span>
    
        <span class="tag">
            <a href="/category/Windows Server">#Windows Server</a>
        </span>
    
  </div>

  <div class="entry">
    <p><em>UPDATE(2017-09-19): Microsoft have officially recognized the bug and have a KB describing the symptoms and workaround much like the below. See here: <a href="https://support.microsoft.com/en-us/help/4043361/disks-in-maintenance-mode-status-after-september-cumulative-update-kb">https://support.microsoft.com/en-us/help/4043361/disks-in-maintenance-mode-status-after-september-cumulative-update-kb</a></em></p>

<p>I was patching our dev cluster the other day and came across a new issue when applying the latest September Cumulative Update (KB4038782), and it seems others on the internet have hit this issue as well.</p>

<h2 id="background">Background</h2>

<p>First, a bit of background on the expected behaviour when performing maintenance:</p>

<p>Basically when you are performing maintenance on a Storage Spaces Direct (S2D) Cluster, you would normally use Failover Cluster Manager (GUI or Powershell) to Pause and Drain the node first, and then patch and reboot it, and eventually resume and fail back its rolls.</p>

<p>Now doing this would in turn, mark the physical disks associated with that host as being in maintenance mode during this period to redirect IO away from them, and then when the host is resumed, the disks are taken out of maintenance mode and IO is resumed to them and the storage re-sync begins.</p>

<p>This is all automated for you if you use the awesome Cluster Aware Updating (CAU) features, which will patch whole clusters for you without your manual involvement.</p>

<h2 id="problem">Problem:</h2>

<p>What I found while patching this month, both manually and with CAU, is that when the hosts go into maintenance mode and are paused and drained, their disks are also marked as being in maintenance mode, however after patching and rebooting, they get resumed but their disks stay in maintenance mode.</p>

<p><a href="https://i2.wp.com/bcthomas.com/wp-content/uploads/2017/09/Screen-Shot-2017-09-17-at-8.22.45-AM.png?ssl=1"><img class="aligncenter size-full wp-image-92" src="https://i2.wp.com/bcthomas.com/wp-content/uploads/2017/09/Screen-Shot-2017-09-17-at-8.22.45-AM.png?resize=558%2C542&#038;ssl=1" alt="" width="558" height="542" srcset="https://i2.wp.com/bcthomas.com/wp-content/uploads/2017/09/Screen-Shot-2017-09-17-at-8.22.45-AM.png?w=558&amp;ssl=1 558w, https://i2.wp.com/bcthomas.com/wp-content/uploads/2017/09/Screen-Shot-2017-09-17-at-8.22.45-AM.png?resize=300%2C291&amp;ssl=1 300w" sizes="(max-width: 558px) 100vw, 558px" data-recalc-dims="1" /></a> <a href="https://i2.wp.com/bcthomas.com/wp-content/uploads/2017/09/Screen-Shot-2017-09-17-at-8.22.15-AM.png?ssl=1"><img class="aligncenter size-large wp-image-91" src="https://i0.wp.com/bcthomas.com/wp-content/uploads/2017/09/Screen-Shot-2017-09-17-at-8.22.15-AM-909x1024.png?resize=640%2C721&#038;ssl=1" alt="" width="640" height="721" srcset="https://i2.wp.com/bcthomas.com/wp-content/uploads/2017/09/Screen-Shot-2017-09-17-at-8.22.15-AM.png?resize=909%2C1024&amp;ssl=1 909w, https://i2.wp.com/bcthomas.com/wp-content/uploads/2017/09/Screen-Shot-2017-09-17-at-8.22.15-AM.png?resize=266%2C300&amp;ssl=1 266w, https://i2.wp.com/bcthomas.com/wp-content/uploads/2017/09/Screen-Shot-2017-09-17-at-8.22.15-AM.png?resize=768%2C865&amp;ssl=1 768w, https://i2.wp.com/bcthomas.com/wp-content/uploads/2017/09/Screen-Shot-2017-09-17-at-8.22.15-AM.png?w=1410&amp;ssl=1 1410w, https://i2.wp.com/bcthomas.com/wp-content/uploads/2017/09/Screen-Shot-2017-09-17-at-8.22.15-AM.png?w=1280 1280w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1" /></a></p>

<p>What this means, is that if you’re using CAU, it will fail to patch the cluster after the first host or two, depending on your resiliency, as it doesn’t have enough spare capacity left to take more disks out of maintenance mode, even though all the hosts are up and healthy.</p>

<p>You can check this by running the following Powershell on a cluster host</p>

<div class="language-powershell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">Get-StorageNode</span> |%<span class="o">{</span><span class="nv">$_</span>.Name;<span class="nv">$_</span> | <span class="nb">Get-PhysicalDisk</span> -PhysicallyConnected<span class="o">}</span>
</code></pre></div></div>

<h2 id="workaround-and-fix">Workaround and Fix</h2>

<p>Now, if you’ve already started patching and need to recover from this, you can use the following Powershell to remediate the hosts you’ve patched</p>

<div class="language-powershell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Repair-ClusterStorageSpacesDirect -Node <span class="o">[</span><span class="nb">hostname</span><span class="o">]</span> -DisableStorageMaintenanceMode
</code></pre></div></div>

<p><a href="https://i0.wp.com/bcthomas.com/wp-content/uploads/2017/09/Screen-Shot-2017-09-17-at-8.57.09-AM.png?ssl=1"><img class="aligncenter size-large wp-image-94" src="https://i0.wp.com/bcthomas.com/wp-content/uploads/2017/09/Screen-Shot-2017-09-17-at-8.57.09-AM-1024x577.png?resize=640%2C361&#038;ssl=1" alt="" width="640" height="361" srcset="https://i0.wp.com/bcthomas.com/wp-content/uploads/2017/09/Screen-Shot-2017-09-17-at-8.57.09-AM.png?resize=1024%2C577&amp;ssl=1 1024w, https://i0.wp.com/bcthomas.com/wp-content/uploads/2017/09/Screen-Shot-2017-09-17-at-8.57.09-AM.png?resize=300%2C169&amp;ssl=1 300w, https://i0.wp.com/bcthomas.com/wp-content/uploads/2017/09/Screen-Shot-2017-09-17-at-8.57.09-AM.png?resize=768%2C433&amp;ssl=1 768w, https://i0.wp.com/bcthomas.com/wp-content/uploads/2017/09/Screen-Shot-2017-09-17-at-8.57.09-AM.png?w=1416&amp;ssl=1 1416w, https://i0.wp.com/bcthomas.com/wp-content/uploads/2017/09/Screen-Shot-2017-09-17-at-8.57.09-AM.png?w=1280 1280w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1" /></a></p>

<p>If you haven’t patched, then you can avoid this by choosing to ‘Pause and Don’t Drain’ your hosts in Failover Cluster Manager, and then manually live migrate your VMs and Virtual Disks to other cluster members before patching and rebooting the host, as this will avoid the physical disks being put into maintenance mode in the first place.</p>

<h2 id="my-take-on-the-problem">My take on the problem</h2>

<p>Having dealt with S2D for a while, I think what we’re seeing here is a change in behaviour to how maintenance is performed on S2D Cluster hosts, and so when this new logic has been pushed out with the September CU, it’s conflicting with the old logic and leaving things in a halfway house.</p>

<p>I very much doubt we will see this problem in next month’s patching, as it looks like once September CU is applied, the issue isn’t reproducible when putting hosts in and out of maintenance mode.</p>

<p>Hopefully this helps anyone else coming across this issue</p>

  </div>

  <div class="date">
    Written on September 17, 2017
  </div>
  
  <div class="related">
    <h3>Related Posts</h3>
    
    
    
        
            
            <a href="/2017/10/must-read-storage-spaces-direct-blog-posts/">Must Read Storage Spaces Direct Blog Posts</a><br>
        

        
    
        

        
    
        
            
            <a href="/2016/11/s2d-storage-tiers-misconfiguration-bug/">S2D Storage Tiers misconfiguration bug</a><br>
        

        
    
        
            
            <a href="/2016/10/expanding-storage-spaces-direct-volumes/">Expanding Storage Spaces Direct Volumes</a><br>
        

        
            
  </div>

  
<div class="comments">
	<div id="disqus_thread"></div>
	<script type="text/javascript">

	    var disqus_shortname = 'ben-thomas-blog';

	    (function() {
	        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
	        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
	        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
	    })();

	</script>
	<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>

</article>

    </div>

    <div class="wrapper-footer">
      <div class="container">
        <footer class="footer">
          
<a href="mailto:ben.thomas@nzgeek.co.nz"><i class="svg-icon email"></i></a>


<a href="https://github.com/comnam90"><i class="svg-icon github"></i></a>



<a href="/feed.xml"><i class="svg-icon rss"></i></a>
<a href="https://www.twitter.com/NZ_BenThomas"><i class="svg-icon twitter"></i></a>



        </footer>
      </div>
    </div>

    

  </body>
</html>
